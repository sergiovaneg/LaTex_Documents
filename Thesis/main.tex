\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{comment}
\usepackage{dirtytalk}

\usepackage{cleveref}

\bibliographystyle{ieeetr}

\begin{document}

\section{The Abstract Koopman Operator} \label{sec:Abstract}

    Koopman operators consist on a dimension lifting technique that allows us to model a Finite Dimensional Nonlinear Dynamical System through an Infinite Dimensional Linear Dynamical System.
    
    Koopman operators provide a convenient framework where traditional, more mature and optimized Linear System Identification and Control tools can be applied to a nonlinear system. In contrast with conventional linearization methods that depend on local derivatives, the Koopman operator provides an exact description (at least in theory) of the system's dynamics and, more importantly from the Applied Controls point of view, it is easily adaptable to a fully data-driven pipeline, provided we have some way of probing the internal states of the system (gray-box framework).

    We start by stating the abstract problem, partially borrowing the definition from MeziÄ‡ et Al.\cite{Koopman_Basics}\cite{Applied_Koopmanism}. Consider a continuous-time dynamical system such as the one given in \cref{eq:CT_Dyn} on the state space $M$, where $\mathbf{x}$ is a coordinate vector of the state, and $\textbf{F}$ is (assumed to be) a non-linear vector-valued smooth function of the same dimension as its argument.

    \begin{equation} \label{eq:CT_Dyn}
        \mathbf{\dot{x}} = \mathbf{F}\left( \mathbf{x} \right) , \mathbf{x} \in M
    \end{equation}
    
    Let $S^t(\mathbf{x}_0)$ denote the position the position at time $t$ of the trajectory of the system in \cref{eq:CT_Dyn} that starts at $t=0$ from the state $\mathbf{x}_0$, and let $g:M \mapsto \mathbb{C}$ an \textit{arbitrary} (at least for now), complex-valued function. We call $g$ an observable of the system in \cref{eq:CT_Dyn}, whose value observed over a trajectory starting from $\mathbf{x}_0$ at $t=0$ changes with time according to the flow, as described in \cref{eq:obs_traj}.

    \begin{equation} \label{eq:obs_traj}
        g\left(t,\mathbf{x}_0\right) = g \left(\mathbf{S}^t\left(\mathbf{x}_0\right)\right)
    \end{equation}
    
    The space $\mathcal{G}$ of all observables such as $g$ is a linear functional space, and thus we can define a family of linear operators $U^t:\mathcal{G} \mapsto \mathcal{G}$ with $t \in \left[0,\infty\right)$ through \cref{eq:Koopman_CT}.

    \begin{equation} \label{eq:Koopman_CT}
        U^t g\left(\mathbf{x}_0\right) = g \left(S^t \left(\mathbf{x}_0\right)\right)
    \end{equation}

    Thus, for a fixed $t$, $U^t$ maps the vector-valued observable $g(\mathbf{x}_0)$ into $g\left(t,\mathbf{x}_0\right)$. We will call the family of all operators $U^t$, indexed by time $t$, the \textbf{Koopman Semigroup} given by the generator $U$ of the continuous-time system in \cref{eq:CT_Dyn}.

    In Discrete Time, the definition is even simpler. Let \cref{eq:DT_Dyn} describe a discrete-time dynamical system with $\mathbf{z} \in M$ and $\mathbf{T}:M \mapsto M$. Then, the associated Koopman operator $U$ is defined by \cref{eq:Koopman_DT}.

    \begin{equation} \label{eq:DT_Dyn}
        \mathbf{z}_{k+1} = \mathbf{T}\left(\mathbf{z}\right) , \left\{\mathbf{z}_k,\mathbf{z}_{k+1}\right\} \subset M
    \end{equation}

    \begin{equation} \label{eq:Koopman_DT}
        U g\left(\mathbf{z}\right) = g \circ \mathbf{T} \left(\mathbf{z}\right)
    \end{equation}

    At this point, it is worth noting that the discrete-time Koopman operator is also linear; i.e., $U\left(c_1 \mathbf{f}_1\left(\mathbf{z}\right) + c_2 \mathbf{f}_2\left(\mathbf{z}\right)\right) =
    c_1 \mathbf{f}_1\left(\mathbf{T}\left(\mathbf{z}\right)\right) + c_2 \mathbf{f}_2\left(\mathbf{T}\left(\mathbf{z}\right)\right) =
    c_1 U\mathbf{f}_1\left(\mathbf{z}\right) + c_2 U\mathbf{f}_2\left(\mathbf{z}\right)$. This linearity allows us to derive \cref{eq:DT_Koopman_Concat}, which implies that the dynamics of the observables of a system over a trajectory $S^k\left(\mathbf{z}_0\right)$ can be entirely described by the consecutive application of the discrete-time Koopman operator without having to \say{observe} the system twice for a single trajectory.

    \begin{equation} \label{eq:DT_Koopman_Concat}
        g \circ \mathbf{T}\left(\mathbf{T}\left(\mathbf{z}_0\right)\right) = U g\left(\mathbf{T}\left(\mathbf{z}_0\right)\right) = U g \circ \mathbf{T} \left(\mathbf{z}_0\right) = U^2 g\left(\mathbf{z}_0\right) , \mathbf{z}_0 \in M
    \end{equation}
    
\begin{comment}
    By taking advantage of this linearity, we can now make use of eigenfunction decomposition in order to obtain further information from the defined operator. We call $\phi : M \mapsto \mathbb{C}$ an eigenfunction of the Koopman operator $U$, associated to an eigenvalue $\lambda \in \mathbb{C}$.
\end{comment}

\section{The Koopman Operator for Data-driven Real System Identification}

    \subsection{Applied problem definition}

        After properly defining the abstract the Koopman operator, we now want to stablish a practical framework in order to make use of its properties for System Identification and Control applications. We start by redefining $M$ as a real vector-space, and we follow the numerical scheme proposed by Mauroy-Goncalves\cite{Goncalves} as a data-driven Identification method for dynamical systems.
        
        We consider the Real Dynamical System described in \cref{eq:CT_Dyn_Real}, where $n$ is the dimension of the system. 

        \begin{equation} \label{eq:CT_Dyn_Real}
            \dot{\mathbf{x}} = \mathbf{F}\left(\mathbf{x}\right), \mathbf{x} \in \mathbb{R}^n
        \end{equation}

        The vector field $\mathbf{F}$ is w.l.o.g. of the form described in \cref{eq:F_Decomp}, where the $k$ vectors $\mathbf{w}_i = \left( w_i^1 \cdots w_i^n \right)^T \in \mathbb{C}^n$ are unknown coefficients to be identified, whereas the $k$ library functions $h_i : \mathbb{R}^n \mapsto \mathbb{C}$ are assumed to be known; note that some coefficients might be zero.

        \begin{equation} \label{eq:F_Decomp}
            \mathbf{F}(\mathbf{x}) = \sum_{i = 1}^{N_F} \mathbf{w}_i h_i \left( \mathbf{x} \right)
        \end{equation}

        Our first goal is to identify the vector field F (i.e., the $N_F$ coefficient vectors $\mathbf{w}_i$) from snapshot measurements of the system trajectories. We consider $K$ snapshot pairs $\left(\mathbf{x}_k,\mathbf{y}_k\right)$ obtained from noisy measurements yielding \cref{eq:x_noisy,eq:y_noisy}, where $\epsilon$ is the state-dependent measurement noise, and \cref{eq:snap}, which is associated to the dynamical system described in \cref{eq:CT_Dyn}.

        \begin{align}
            \mathbf{x}_k &= \bar{\mathbf{x}}_k + \epsilon\left(\mathbf{x}_k\right) \label{eq:x_noisy} \\
            \mathbf{y}_k &= \bar{\mathbf{y}}_k + \epsilon\left(\mathbf{y}_k\right) \label{eq:y_noisy} \\
            \mathbf{y}_k &= \mathbf{S}^{T_s}\left(\mathbf{x}_k\right) \label{eq:snap}
        \end{align}

        We assume that the measurement noise is Gaussian and proportional to the state value; i.e., $\epsilon\left(\mathbf{x}\right) = \mathbf{x} \cdot \mathbf{\eta} , \eta \sim \mathcal{N}\left(0,\sigma_\text{meas}\right)$. We also assume all snapshot pairs lie in a compact set $X \subset \mathbb{R}^n$ and are obtained with the same sampling time $T_s$, but we are not compelled to extracting all samples from the same trajectory (i.e., associated to the same starting point $\mathbf{z}_0$).
    
    \subsection{Applied Koopman operator}

        As we stated in \cref{sec:Abstract}, we can alternatively describe the behavior of the system  through a collection of \textit{observables} $g : \mathbb{R}^n \mapsto \mathbb{C}$ in a lifted space instead of using the original system states. Provided that the functions are continuously differentiable, their dynamics in the lifted space are given by \cref{eq:obs_dyn}, where $\dot{g}$ denotes $\frac{\partial \left(f \circ \mathbf{S}^t\right)}{\partial t}$ and $\nabla$ denotes the gradient.

        \begin{equation} \label{eq:obs_dyn}
            \dot{g} = \left(\mathbf{F} \cdot \nabla\right) g , g \in \mathcal{G}
        \end{equation}

        In contrast to \cref{eq:CT_Dyn_Real}, the dynamics in \cref{eq:obs_dyn} are now infinite dimensional, but linear. Not only that, but we can also recover the semigroup-driven dynamics described in \cref{eq:Koopman_CT}. That means that while the original state-space flow induced by \cref{eq:CT_Dyn_Real} is given by the nonlinear flow map $S^t$, the flow induced by \cref{eq:obs_dyn} in the lifted space $\mathcal{G}$ is given by the linear semigroup of Koopman operators $U^t$ behaving just as in \cref{eq:obs_traj}.
        
        Under appropriate conditions (see \cite{Goncalves}), the semigroup of Koopman operators is strongly continuous and generated by the operator $L$ in \ref{eq:infinitesimal_gen}, which we will call the infinitesimal generator of the Koopman operator; we denote its domain by $\mathcal{D} \left(L\right)$.

        \begin{equation} \label{eq:infinitesimal_gen}
            L = \mathbf{F} \cdot \nabla \implies U^t = e^{Lt}
        \end{equation}

        We will later exploit this continuity to manipulate the inherent sample time of the desired discrete Koopman operator, since this versatility turns out to be really helpful when controlling a real system.

    \subsection{Linear identification in the Lifted Space}

        The semigroup of Koopman operators $U^t$ that describes the flow $S^t$ is unique for each system. It is by exploiting this equivalence relation that we can set ourselves to recover the system dynamics entirely from the Lifted Space. We divide the identification into three main steps:

        \begin{itemize}
            \item \textit{Data lifting:} the snapshot pairs $\left(\mathbf{x}_k,\mathbf{y}_k\right)$ described in \cref{eq:snap} are lifted to the space of observables by constructing new pairs of the form\\$\left(\mathbf{g}\left(\mathbf{x}_k\right),\mathbf{g}\left(\mathbf{y}_k\right)\right)$ for some $\mathbf{g} = \left\{g_j\right\}_{j=1}^{N} \subset \mathcal{G}$; each \textit{basis function} $g_j$ is assumed to be continuously differentiable. \Cref{eq:Koopman_snap} follows from \cref{eq:x_noisy,eq:y_noisy,eq:snap}.
            
            \begin{align} \label{eq:Koopman_snap}
                \mathbf{g} \left(\mathbf{y}_k\right) &= \mathbf{g} \left(S^{T_s} \left(\mathbf{x}_k - \epsilon\left(\mathbf{x}_k\right)\right) + \epsilon\left(\mathbf{y}_k\right)\right)
                \\
                & \approx U^{T_s} \mathbf{b}\left(\mathbf{x}_k\right) + \mathcal{O} \left(\left|\left|\epsilon\right|\right|\right)
            \end{align}

            \item \textit{Identification of the Koopman operator:} A truncated finite-dimensional projection of the Koopman operator is obtained through a classical linear identification method, similar to a component of the Extended DMD algorithm\cite{EDMD}, which in turn yields an approximation of the infinitesimal generator from \ref{eq:infinitesimal_gen}.
            
            \item \textit{Identification of the vector field:} Using \ref{eq:infinitesimal_gen}, we can recover the original system's vector field $F$.
        \end{itemize}

        The specifics of each step will be discussed in \cref{sec:algorithm}.

\section{Lifting Algorithm} \label{sec:algorithm}

    \subsection{First Step: Data lifting}

        At this point, a choice has to be made: so far, we have treated the library of observables as an infinite collection with all possible functions of the form $g:M \mapsto \mathbb{C}$; nevertheless, in practice such a collection is unfeasible, which is why we have to analyze the Koopman operator over a truncated realization of the theoretical functional space.

        % Add proper references to real world applications and other benchmarks
        The selection of the observable functions can be completely arbitrary (see \dots) or even physically-informed (see \dots). Nevertheless, for the sake of generality, we will present the algorithm using a sequence of monomials. These are not only congruent with the classical theory of Taylor expansion of arbitrary functions, but also facilitate scalability both in order and dimension while still providing a numerically trackable way of reaching a (theoretical) complete basis.

        Let $\mathcal{F}_N \subset \mathcal{F}$ be the linear subspace of observables generated by the basis $\left\{g_j\right\}_{j=1}^{N} = \left\{p_j\right\}_{j=1}^{N}$ of all polynomials of the form $p_j = x_1^{s_{j_1}} \cdots x_n^{s_{j_n}}$ with total degree lesser or equal than $m$, so that $N = \frac{(n+m)!}{n!m!}$.

        For each snapshot pair $\left(\mathbf{x}_k,\mathbf{y}_k\right) \in \mathbb{R}^{n \times 2} , k \in \left\{1,\dots,K\right\}$, we construct a new pair $\left(\mathbf{p}\left(\mathbf{x}_k\right),\mathbf{p}\left(\mathbf{y}_k\right)\right) \in \mathbb{R}^{N \times 2}$, where $\mathbf{p}\left(\mathbf{x}\right) = \left(p_1\left(\mathbf{x}\right) , \dots p_N\left(\mathbf{x}\right)\right)^T$ denotes the vector of basis monomials under the above constraints. From now on, we will also use the $\mathbb{R}^{K \times N}$ matrices in \cref{eq:snap_matrix}.

        \begin{equation} \label{eq:snap_matrix}
            \mathbf{P_x} =
            \begin{pmatrix}
                \mathbf{p}\left(\mathbf{x}_1\right)^T \\
                \vdots \\
                \mathbf{p}\left(\mathbf{x}_K\right)^T
            \end{pmatrix}
            \qquad
            \mathbf{P_y} =
            \begin{pmatrix}
                \mathbf{p}\left(\mathbf{y}_1\right)^T \\
                \vdots \\
                \mathbf{p}\left(\mathbf{y}_K\right)^T
            \end{pmatrix}
        \end{equation}

    \subsection{Second Step: Identification of the Koopman operator}

        Now, we proceed with the identification of the Koopman operator $U^t , t = T_s$; specifically, we will identify the finite-rank truncation $U_N: \mathcal{G}_N \mapsto \mathcal{G}_N$ of the form $U_N = P_N \left.U^{T_s}\right|_{\mathcal{G}_N}$, where $P_N : L\left(\mathcal{G}\right) \mapsto L\left(\mathcal{G}_N\right)$ is the projection operator onto the subspace $L\left(\mathcal{G}_N\right)$ of Linear Functionals and where $\left.U^{T_s}\right|_{\mathcal{G}_N} : \mathcal{G}_N \mapsto \mathcal{G}$ is the restriction of the Infinite-Dimensional Koopman operator to the truncated subspace of observables $\mathcal{G}_N$.
        
        Consider equation \cref{eq:trunc_dyn}, where we exploit the linearity of the Koopman operator in the vector space to describe the dynamics of the polynomial observables through a pair of coefficient vectors $\left(\mathbf{a},\mathbf{b}\right) \in \mathbb{R}^{N \times 2}$ (arbitrary as long as they comply with the aforementioned expression), we can define a matrix $\overline{\mathbf{U}}_N \in \mathbb{R}^{N \times N}$ that satisfies \cref{eq:UN_Matrix}.

        \begin{equation} \label{eq:trunc_dyn}
            g = \mathbf{a}^T \mathbf{p} , \quad U_N g = \mathbf{b}^T \mathbf{p}
        \end{equation}

        \begin{equation} \label{eq:UN_Matrix}
            \overline{\mathbf{U}}_N \mathbf{a} = \mathbf{b}
        \end{equation}

        The matrix $\overline{\mathbf{U}}_N$ is a representation of the projected Koopman operator $U_N$, providing an approximate finite-dimensional linear description of the nonlinear system in the truncated space of observables. As previously mentioned, this approximation does not depend on local linearization techniques, which makes it valid globally (granted sufficient trajectories covering all present dynamics were fed to the algorithm).

        \Cref{eq:Koopman_to_Matrix_1} follows from \cref{eq:trunc_dyn,eq:UN_Matrix} and, since this holds for all coefficient vectors $\mathbf{a}$, we get \cref{eq:Koopman_to_Matrix_2}, where the operator $U_N$ acts on each component of the polynomial vector $\mathbf{p}$. This implies that the $j$-th column of the resulting matrix is associated to the projection onto $\mathcal{F}_N$ of the image of the basis function $p_j$ through the finite-rank Koopman operator $U_N^{T_s}$.

        \begin{equation} \label{eq:Koopman_to_Matrix_1}
            U_N g = U_N \left(\mathbf{a}^T \mathbf{p}\right) = \left(\overline{\mathbf{U}}_N \mathbf{a}\right)^T \mathbf{p} = \mathbf{p}^T \overline{\mathbf{U}}_N \mathbf{a}
        \end{equation}

        \begin{equation} \label{eq:Koopman_to_Matrix_2}
            U_N \mathbf{p}^T = \mathbf{p}^T \overline{\mathbf{U}}_N
        \end{equation}

        We now get the least-squares fit for the orthogonal projection of an observable by solving the minimization problem in \cref{eq:PN_Min_Prob}, which yields the expression presented in \cref{eq:PN_Min_Sol} where $\mathbf{P}^\dagger$ denotes the Moore-Penrose pseudo-inverse of $\mathbf{P}$.

        \begin{equation} \label{eq:PN_Min_Prob}
            P_N g = \text{arg min}_{\tilde{g} \in \text{span}\left\{p_1 , \dots , p_N\right\}} \sum_{k=1}^K \left|\tilde{g}\left(\mathbf{x}_k\right) - g\left(\mathbf{x}_k\right)\right|^2
        \end{equation}

        \begin{equation} \label{eq:PN_Min_Sol}
            P_N g = \mathbf{p}^T \mathbf{P_x}^\dagger
                \begin{pmatrix}
                    g\left(\mathbf{x}_1\right) \\
                    \vdots \\
                    g\left(\mathbf{x}_K\right)
                \end{pmatrix}
        \end{equation}

        % Replace Goncalves cite with a more detailed demonstration of the measurement noise effect
        The above means that we can get the least-squares coefficients associated to the projection of the $j$-th polynomial observable by setting $g=U^{T_s} p_j$ and using \cref{eq:PN_Min_j}, under the assumption that the measurement noise $\left|\left|\epsilon\right|\right|$ is small enough \cite{Goncalves}.

        \begin{equation} \label{eq:PN_Min_j}
            P_N \left(U^{T_s} p_j\right) = \mathbf{p}^T \mathbf{P_x}^\dagger
                \begin{pmatrix}
                    U^{T_s} p_j\left(\mathbf{x}_1\right) \\
                    \vdots \\
                    U^{T_s} p_j\left(\mathbf{x}_K\right)
                \end{pmatrix}
            \approx \mathbf{p}^T \mathbf{P_x}^\dagger
                \begin{pmatrix}
                    p_j\left(\mathbf{y}_1\right) \\
                    \vdots \\
                    p_j\left(\mathbf{y}_K\right)
                \end{pmatrix}
        \end{equation}

        By concatenating the above expression for all polynomial observables we get \cref{eq:UN_Final}, which corresponds to the least-squares approximation of the matrix representation of the truncated Koopman operator indexed by the sampling time $T_s$.

        \begin{equation} \label{eq:UN_Final}
            \overline{\mathbf{U}}_N \approx \mathbf{P}_x^\dagger \mathbf{P}_y
        \end{equation}

    \bibliography{main.bib}

\end{document}